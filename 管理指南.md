# 硬件要求[¶](https://docs.daos.io/v2.2/admin/hardware/#hardware-requirements)

本节的目的是描述部署 DAOS 系统的处理器、存储和网络要求。

## 部署选项

DAOS 存储系统部署为**池存储模型**。DAOS 服务器可以在单独机架中的专用存储节点上运行。这是一种传统的池模型，其中存储由所有计算节点统一访问。为了最大限度地减少 I/O 机架的数量并优化占地面积，这种方法通常需要高密度存储服务器。

## 处理器要求

DAOS 需要 64 位处理器架构，主要基于英特尔x86_64架构开发。DAOS 软件及其依赖的库（例如 [ISA-L](https://github.com/intel/isa-l)、SPDK、[PMDK 和 DPDK](https://spdk.io/)）可以利用英特尔英特尔 SIMD 流指令 （SSE） 和英特尔高级矢量 （AVX） 扩展。

社区还报告了在以小端模式配置的 64 位 ARM 处理器上运行 DAOS 客户端的一些成功。话虽如此，ARM 测试不是当前 DAOS CI 管道的一部分，因此不会定期进行验证。

## 网络要求

支持RDMA的结构是首选，以获得最佳性能。DAOS 数据平面依赖于 OFI [libfabric](https://ofiwg.github.io/libfabric/)，并支持以太网/tcp 和 InfiniBand/动词的 OFI 提供程序。从 DAOS 2.2 中的技术预览开始，[UCX](https://www.openucx.org/) 也支持 DAOS 的替代网络堆栈。请参阅 UCX 结构支持（DAOS [2.2 技术预览版），了解有关使用 UCX 支持 设置 DAOS](https://docs.daos.io/v2.2/admin/ucx/) 的详细信息。

DAOS 通过将 DAOS 引擎的不同实例绑定到单个网卡来支持服务器上的多个网络接口。DAOS 可以通过将节点上的不同客户端进程分配给不同的网络接口来支持客户端上的多个网络接口。请注意，DAOS *不支持*跨多个网络接口的网络级条带化，因此单个客户端进程将始终使用*单个*网络链接。

DAOS 控制平面提供了使用安全套接字层接口管理和管理 DAOS 服务器的方法。客户端和服务器之间的管理流量使用结构上的 IP。但是，在大型集群上，DAOS 服务器的管理通常使用额外的带外网络连接 DAOS 服务集群中的节点。

## 存储要求

DAOS 要求每个存储节点能够直接访问存储类内存 （SCM）。虽然 DAOS 主要针对英特尔傲腾^TM^ 持久内存进行测试和调优，但 DAOS 软件堆栈基于 Linux 操作系统的持久内存开发套件 （PMDK） 和直接访问 （DAX） 功能构建，如 [SNIA NVM 编程模型](https://www.snia.org/sites/default/files/technical_work/final/NVMProgrammingModel_v1.2.pdf)中所述。因此，开源 DAOS 软件堆栈应该能够在 PMDK 支持的任何存储类内存上透明地运行。

存储节点可以选择配备 [NVMe](https://nvmexpress.org/)（非易失性内存快递）[^10] SSD 以提供容量。HDD 以及 SATA 和 SAS SSD 不受 DAOS 支持。NVMe 3D-NAND 和 Optane SSD 均受支持 NVMe 3D-NAND 和 Optane SSD。傲腾固态硬盘是针对非常高 IOPS 速率的 DAOS 安装的首选。NVMe-oF 设备也受用户空间存储堆栈支持，但从未经过测试。

SCM 与 SSD 容量的至少 6% 比率将保证 DAOS 在 SCM 中有足够的空间来存储其内部元数据（例如，池元数据、SSD 块分配跟踪）。较低的比率是可能的，但所需的 SCM 数量将取决于访问 DAOS 存储的应用程序的使用模式。由于 DAOS 将 SCM 用于其元数据，如果比率太低，则可能有可用的大容量存储，但 DAOS 元数据的 SCM 不足。

出于测试目的，可以通过挂载 tmpfs 文件系统来使用 DRAM 模拟 SCM，并且 NVMe SSD 也可以使用 DRAM 或环回文件进行模拟。

## 存储服务器设计

DAOS 存储服务器的硬件设计平衡了结构的网络带宽与 NVMe 存储设备的总存储带宽。此关系根据应用程序工作负载的读/写平衡设置 NVMe 驱动器的数量。由于 NVMe SSD 的读取速度比写入速度快，因此 200Gbps PCIe4 x4 NIC 可以通过 4 个 NVMe4 x4 SSD 为只读工作负载进行平衡，但对于 8 个 NVMe4 x4 SSD 的写入工作负载进行平衡。SSD 的容量将决定为 DAOS 元数据提供 6% 比率所需的傲腾 PMem DIMM 的最小容量。

![img](https://docs.daos.io/v2.2/admin/media/image2.png)

## CPU 关联性

最近的英特尔至强数据中心平台使用两个处理器 CPU，通过超级路径互连 （UPI） 连接在一起。这些服务器中的 PCIe 通道与一个 CPU 具有天然的关联性。尽管可以从任何系统内核全局访问，但通过 PCIe 总线连接的 NVMe SSD 和网络接口卡可以为每个 CPU 提供不同的性能特征（例如，更高的延迟、更低的带宽）。访问非本地 PCIe 设备可能涉及通过 UPI 链路的流量，这可能会成为拥塞点。同样，持久内存是非统一可访问的 （NUMA），并且必须考虑 CPU 关联性才能获得最大性能。

因此，在多插槽和多轨环境中运行时，DAOS 服务必须能够检测 CPU 到 PCIe 设备和持久内存的关联性，并尽可能减少非本地访问。这可以通过为每个 CPU 生成一个 I/O 引擎实例，然后仅从该服务器实例访问该 CPU 本地的持久内存和 PCI 设备来实现。DAOS 控制平面负责检测存储和网络亲和性，并相应地启动 I/O 引擎。

![img](https://docs.daos.io/v2.2/admin/hardware/media/image3.png)

## 容错域

DAOS 依赖于大量分布在不同存储节点上的单端口存储。因此，每个存储节点都是一个单点故障。DAOS 通过跨不同容错域中的存储节点提供数据冗余来实现容错。

DAOS 假定容错域是分层的，不会重叠。例如，容错域的第一级可以是机架，第二级可以是存储节点。

为了实现高效放置和最佳数据弹性，容错域越多越好。因此，最好将存储节点分布在尽可能多的机架上。